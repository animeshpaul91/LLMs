### Generative AI Applications
- Writing - Press Release, Brainstorming etc.
- Reading - Proofreading, Summarizing. Example is - summarizing conversations between customers & agents or gathering customer sentiments.
- Chatting - Building specialized chatbots. Eg - Trip/Travel planner, Recipe Generator, IT Service chatbot.


### What LLMs can and cannot do?
- A mental framework is to ask a fresh college graduate on if they would be able to follow the instructions in the prompt to complete the task.
- Knowledge Cutoff (knowledge upto a certain date) for LLMs. Even though modern LLMs can scrape the web in real time.
- Hallucinations: A confident or authoritative instance in which an LLM creates/Makes facts up.
- Limits on Input + Output or Input prompt length.
- Generative AI does not seem to work well with structured data.
- Generative AI seems to work well with structured data.
- LLMs could reflect biases in the text that it learned from.


### Tips on Prompting LLMs
- Be detailed and specific.
- Guide the model to think through its answer.
- Experiment and iterate. Start of with something and seeing if the results are satisfactory and adjusting the prompt to get a more accurate and a finer response.
- Do not overthink the initial prompt - quickly give it some context, then prompt the LLM to get its response, see what you get and iteratively refine your prompt from there.


### What is a Token?
Token is the most fundamental subset of a word which the LLM processes as a single atomic unit. It is loosely a word or a sub-part of a word. Roughly 1 token = (3/4) words.